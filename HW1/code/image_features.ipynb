{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from skimage.feature import hog\n",
    "from skimage import data\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHA = 3\n",
    "CPU_USED = 100\n",
    "RANDOM_STATE = 11\n",
    "RS = np.random.RandomState(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Train Val Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image2np(img_path:str):\n",
    "    global IMG_WIDTH, IMG_HEIGHT, IMG_CHA\n",
    "    img_path = f\"../raw_data/{img_path}\"\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "def load_data(meta_path:str):\n",
    "    # with multiprocessing to speed up loading img\n",
    "    global CPU_USED\n",
    "    with open(meta_path, 'r') as f:\n",
    "        data_path = [line.strip().split(' ') for line in f.readlines()]\n",
    "        X, y = zip(*data_path)\n",
    "        \n",
    "        pool = Pool(CPU_USED)\n",
    "        pool_outputs = list(tqdm(pool.imap(load_image2np, X), total=len(X)))\n",
    "        X = np.concatenate(pool_outputs, axis=0)\n",
    "        y = [int(i) for i in y]\n",
    "        y = np.array(y)\n",
    "        return X, y\n",
    "        # 50s\n",
    "\n",
    "def union_shuffle(X, y):\n",
    "    global RS\n",
    "    index = np.arange(X.shape[0])\n",
    "    # np shuffle is inplace edit\n",
    "    RS.shuffle(index)\n",
    "    return X[index], y[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [01:07<00:00, 936.42it/s] \n",
      "100%|██████████| 450/450 [00:00<00:00, 929.50it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 1041.61it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = load_data('../raw_data/train.txt')\n",
    "val_X, val_y = load_data('../raw_data/val.txt')\n",
    "test_X, test_y = load_data('../raw_data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "train_X, train_y = union_shuffle(train_X, train_y)\n",
    "test_X, test_y = union_shuffle(test_X, test_y)\n",
    "val_X, val_y = union_shuffle(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  shape:  (63325, 256, 256, 3)\n",
      "Val    shape:  (450, 256, 256, 3)\n",
      "Test   shape:  (450, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print('{:<6} shape: '.format('Train'), train_X.shape)\n",
    "print('{:<6} shape: '.format('Val'), val_X.shape)\n",
    "print('{:<6} shape: '.format('Test'), test_X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### color histogram\n",
    "[OpenCV-python学习笔记（三）histograms直方图](https://blog.csdn.net/cliukai/article/details/101379638)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_hist(img):\n",
    "    blue, green, red = cv2.split(img)\n",
    "    bg_hist = cv2.calcHist([blue, green], [0, 1], None, [16, 16], [0, 256, 0, 256]).reshape((-1, ))\n",
    "    br_hist = cv2.calcHist([blue, red], [0, 1], None, [16, 16], [0, 256, 0, 256]).reshape((-1, ))\n",
    "    gr_hist = cv2.calcHist([green, red], [0, 1], None, [16, 16], [0, 256, 0, 256]).reshape((-1, ))\n",
    "    return np.concatenate([bg_hist, br_hist, gr_hist])\n",
    "\n",
    "X_color_hist = extract_color_hist(train_X[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historgram of Gradient\n",
    "[HOG算法以及python实现](https://www.cnblogs.com/Asp1rant/p/16545025.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_gradient_hist(img):\n",
    "    fd, hog_img = hog(img, orientations=9, pixels_per_cell=(32, 32), visualize=True,\n",
    "                    cells_per_block=(1, 1), channel_axis=-1)\n",
    "    cv2.imwrite('test.png', hog_img)\n",
    "    return fd\n",
    "\n",
    "extract_gradient_hist(train_X[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(img):\n",
    "    color_outputs = extract_color_hist(img)\n",
    "    hog_outputs = extract_gradient_hist(img)\n",
    "    full_features = np.concatenate([color_outputs, hog_outputs], axis=0)\n",
    "    full_features = np.expand_dims(full_features, axis=0)\n",
    "    return full_features\n",
    "\n",
    "def calc_features(X):\n",
    "    global CPU_USED\n",
    "    pool = Pool(CPU_USED)\n",
    "    pool_outputs = list(tqdm(pool.imap(combine_features, X), total=len(X)))\n",
    "    X_feat = np.concatenate(pool_outputs, axis=0)\n",
    "    return X_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [02:25<00:00, 436.34it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 749.38it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 784.13it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X = calc_features(train_X)\n",
    "val_X = calc_features(val_X)\n",
    "test_X = calc_features(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  shape:  (63325, 1344)\n",
      "Val    shape:  (450, 1344)\n",
      "Test   shape:  (450, 1344)\n"
     ]
    }
   ],
   "source": [
    "print('{:<6} shape: '.format('Train'), train_X.shape)\n",
    "print('{:<6} shape: '.format('Val'), val_X.shape)\n",
    "print('{:<6} shape: '.format('Test'), test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('output/train_features.npz', X=train_X, y=train_y)\n",
    "np.savez('output/val_features.npz', X=val_X, y=val_y)\n",
    "np.savez('output/test_features.npz', X=test_X, y=test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterhub",
   "language": "python",
   "name": "jupyterhub"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
