{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from skimage.feature import hog\n",
    "from skimage import data\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHA = 3\n",
    "CPU_USED = 100\n",
    "RANDOM_STATE = 11\n",
    "RS = np.random.RandomState(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Train Val Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image2np(img_path:str):\n",
    "    global IMG_WIDTH, IMG_HEIGHT, IMG_CHA\n",
    "    img_path = f\"../raw_data/{img_path}\"\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "def load_data(meta_path:str):\n",
    "    # with multiprocessing to speed up loading img\n",
    "    global CPU_USED\n",
    "    with open(meta_path, 'r') as f:\n",
    "        data_path = [line.strip().split(' ') for line in f.readlines()]\n",
    "        X, y = zip(*data_path)\n",
    "        \n",
    "        pool = Pool(CPU_USED)\n",
    "        pool_outputs = list(tqdm(pool.imap(load_image2np, X), total=len(X)))\n",
    "        X = np.concatenate(pool_outputs, axis=0)\n",
    "        y = [int(i) for i in y]\n",
    "        y = np.array(y)\n",
    "        return X, y\n",
    "        # 50s\n",
    "\n",
    "def union_shuffle(X, y):\n",
    "    global RS\n",
    "    index = np.arange(X.shape[0])\n",
    "    # np shuffle is inplace edit\n",
    "    RS.shuffle(index)\n",
    "    return X[index], y[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = load_data('../raw_data/train.txt')\n",
    "val_X, val_y = load_data('../raw_data/val.txt')\n",
    "test_X, test_y = load_data('../raw_data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# shuffle data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_X, train_y \u001b[39m=\u001b[39m union_shuffle(train_X, train_y)\n\u001b[1;32m      3\u001b[0m test_X, test_y \u001b[39m=\u001b[39m union_shuffle(test_X, test_y)\n\u001b[1;32m      4\u001b[0m val_X, val_y \u001b[39m=\u001b[39m union_shuffle(val_X, val_y)\n",
      "Cell \u001b[0;32mIn [3], line 27\u001b[0m, in \u001b[0;36munion_shuffle\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     25\u001b[0m index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m     26\u001b[0m \u001b[39m# np shuffle is inplace edit\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m RS\u001b[39m.\u001b[39mshuffle(index)\n\u001b[1;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m X[index], y[index]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RS' is not defined"
     ]
    }
   ],
   "source": [
    "# shuffle data\n",
    "train_X, train_y = union_shuffle(train_X, train_y)\n",
    "test_X, test_y = union_shuffle(test_X, test_y)\n",
    "val_X, val_y = union_shuffle(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  shape:  (63325, 256, 256, 3)\n",
      "Val    shape:  (450, 256, 256, 3)\n",
      "Test   shape:  (450, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print('{:<6} shape: '.format('Train'), train_X.shape)\n",
    "print('{:<6} shape: '.format('Val'), val_X.shape)\n",
    "print('{:<6} shape: '.format('Test'), test_X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### color histogram\n",
    "[OpenCV-python学习笔记（三）histograms直方图](https://blog.csdn.net/cliukai/article/details/101379638)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_hist(img):\n",
    "    blue, green, red = cv2.split(img)\n",
    "    bg_hist = cv2.calcHist([blue, green], [0, 1], None, [16, 16], [0, 256, 0, 256]).reshape((-1, ))\n",
    "    br_hist = cv2.calcHist([blue, red], [0, 1], None, [16, 16], [0, 256, 0, 256]).reshape((-1, ))\n",
    "    gr_hist = cv2.calcHist([green, red], [0, 1], None, [16, 16], [0, 256, 0, 256]).reshape((-1, ))\n",
    "    return np.concatenate([bg_hist, br_hist, gr_hist])\n",
    "\n",
    "X_color_hist = extract_color_hist(train_X[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historgram of Gradient\n",
    "[HOG算法以及python实现](https://www.cnblogs.com/Asp1rant/p/16545025.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only images with two spatial dimensions are supported. If using with color/multichannel images, specify `channel_axis`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     cv2\u001b[39m.\u001b[39mimwrite(\u001b[39m'\u001b[39m\u001b[39mtest.png\u001b[39m\u001b[39m'\u001b[39m, hog_img)\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m fd\n\u001b[0;32m----> 7\u001b[0m extract_gradient_hist(train_X[\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn [14], line 2\u001b[0m, in \u001b[0;36mextract_gradient_hist\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_gradient_hist\u001b[39m(img):\n\u001b[0;32m----> 2\u001b[0m     fd, hog_img \u001b[39m=\u001b[39m hog(img, orientations\u001b[39m=\u001b[39;49m\u001b[39m9\u001b[39;49m, pixels_per_cell\u001b[39m=\u001b[39;49m(\u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m), visualize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      3\u001b[0m                     cells_per_block\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m), channel_axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m     cv2\u001b[39m.\u001b[39mimwrite(\u001b[39m'\u001b[39m\u001b[39mtest.png\u001b[39m\u001b[39m'\u001b[39m, hog_img)\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m fd\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterhub/lib/python3.9/site-packages/skimage/_shared/utils.py:406\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    403\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39monly a single channel axis is currently suported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    405\u001b[0m \u001b[39mif\u001b[39;00m channel_axis \u001b[39m==\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,) \u001b[39mor\u001b[39;00m channel_axis \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marg_positions:\n\u001b[1;32m    409\u001b[0m     new_args \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterhub/lib/python3.9/site-packages/skimage/_shared/utils.py:348\u001b[0m, in \u001b[0;36mdeprecate_multichannel_kwarg.__call__.<locals>.fixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mchannel_axis\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m convert[kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmultichannel\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m    347\u001b[0m \u001b[39m# Call the function with the fixed arguments\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterhub/lib/python3.9/site-packages/skimage/feature/_hog.py:161\u001b[0m, in \u001b[0;36mhog\u001b[0;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, multichannel, channel_axis)\u001b[0m\n\u001b[1;32m    159\u001b[0m ndim_spatial \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m multichannel \u001b[39melse\u001b[39;00m image\u001b[39m.\u001b[39mndim\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m ndim_spatial \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOnly images with two spatial dimensions are \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    162\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39msupported. If using with color/multichannel \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mimages, specify `channel_axis`.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mThe first stage applies an optional global image normalization\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mequalisation that is designed to reduce the influence of illumination\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mshadowing and illumination variations.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m transform_sqrt:\n",
      "\u001b[0;31mValueError\u001b[0m: Only images with two spatial dimensions are supported. If using with color/multichannel images, specify `channel_axis`."
     ]
    }
   ],
   "source": [
    "def extract_gradient_hist(img):\n",
    "    fd, hog_img = hog(img, orientations=9, pixels_per_cell=(32, 32), visualize=True,\n",
    "                    cells_per_block=(1, 1), channel_axis=-1)\n",
    "    cv2.imwrite('test.png', hog_img)\n",
    "    return fd\n",
    "\n",
    "extract_gradient_hist(train_X[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(img):\n",
    "    color_outputs = extract_color_hist(img)\n",
    "    hog_outputs = extract_gradient_hist(img)\n",
    "    full_features = np.concatenate([color_outputs, hog_outputs], axis=0)\n",
    "    full_features = np.expand_dims(full_features, axis=0)\n",
    "    return full_features\n",
    "\n",
    "def calc_features(X):\n",
    "    global CPU_USED\n",
    "    pool = Pool(CPU_USED)\n",
    "    pool_outputs = list(tqdm(pool.imap(combine_features, X), total=len(X)))\n",
    "    X_feat = np.concatenate(pool_outputs, axis=0)\n",
    "    return X_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [00:52<00:00, 1217.49it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 784.06it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 696.74it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X = calc_features(train_X)\n",
    "val_X = calc_features(val_X)\n",
    "test_X = calc_features(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  shape:  (63325, 1344)\n",
      "Val    shape:  (450, 1344)\n",
      "Test   shape:  (450, 1344)\n"
     ]
    }
   ],
   "source": [
    "print('{:<6} shape: '.format('Train'), train_X.shape)\n",
    "print('{:<6} shape: '.format('Val'), val_X.shape)\n",
    "print('{:<6} shape: '.format('Test'), test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('output/train_features.npz', X=train_X, y=train_y)\n",
    "np.savez('output/val_features.npz', X=val_X, y=val_y)\n",
    "np.savez('output/test_features.npz', X=test_X, y=test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterhub",
   "language": "python",
   "name": "jupyterhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
